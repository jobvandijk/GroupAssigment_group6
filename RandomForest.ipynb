{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16052\\3222368375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Split dataset into training set and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Create a RandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jaspe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                     )\n\u001b[0;32m    213\u001b[0m                 ):\n\u001b[1;32m--> 214\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                 \u001b[1;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jaspe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2648\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2649\u001b[1;33m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[0;32m   2650\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2651\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\jaspe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2305\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   2306\u001b[0m             \u001b[1;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2307\u001b[0m             \u001b[1;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "# Load the training data\n",
    "train_file_path = 'Test set with MACCS keys.csv'\n",
    "df = pd.read_csv(train_file_path)\n",
    "\n",
    "# Convert the 'maccs_keys_bitstring' column to a DataFrame of binary features\n",
    "maccs_keys_df = df['maccs_keys_bitstring'].apply(ast.literal_eval).apply(pd.Series)\n",
    "\n",
    "# Rename columns to indicate they are from MACCS keys\n",
    "maccs_keys_df.columns = [f'maccs_key_{i}' for i in range(maccs_keys_df.shape[1])]\n",
    "\n",
    "# Drop the original 'maccs_keys' and 'maccs_keys_bitstring' columns\n",
    "df = df.drop(columns=['maccs_keys', 'maccs_keys_bitstring'])\n",
    "\n",
    "# Concatenate the new MACCS keys features with the original dataframe\n",
    "df = pd.concat([df, maccs_keys_df], axis=1)\n",
    "\n",
    "# Define the features and target variables\n",
    "X = df.drop(columns=['SMILES', 'PKM2_inhibition', 'ERK2_inhibition'])\n",
    "y = df[['PKM2_inhibition', 'ERK2_inhibition']]\n",
    "\n",
    "# Remove rows with missing target values in y and corresponding rows in X\n",
    "non_missing_indices = y.dropna().index\n",
    "X = X.loc[non_missing_indices]\n",
    "y = y.loc[non_missing_indices]\n",
    "\n",
    "# Convert data to float32\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "val_accuracy = metrics.accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Create a dataframe to compare the actual and predicted values\n",
    "results_df = pd.DataFrame({\n",
    "    'Molecule': df.loc[y_val.index, 'SMILES'],\n",
    "    'PKM2_actual': y_val['PKM2_inhibition'].values,\n",
    "    'ERK2_actual': y_val['ERK2_inhibition'].values,\n",
    "    'PKM2_predicted': y_val_pred[:, 0],\n",
    "    'ERK2_predicted': y_val_pred[:, 1]\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_file_path = \"/mnt/data/predicted_molecules.csv\"\n",
    "results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Calculate feature importances\n",
    "feature_imp = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot the top 10 feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_imp.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.show()\n",
    "\n",
    "# Load the test data\n",
    "test_file_path = 'Test set with MACCS keys.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "# Convert the 'maccs_keys_bitstring' column to a DataFrame of binary features in the test set\n",
    "test_maccs_keys_df = test_df['maccs_keys_bitstring'].apply(ast.literal_eval).apply(pd.Series)\n",
    "\n",
    "# Rename columns to indicate they are from MACCS keys\n",
    "test_maccs_keys_df.columns = [f'maccs_key_{i}' for i in range(test_maccs_keys_df.shape[1])]\n",
    "\n",
    "# Drop the original 'maccs_keys' and 'maccs_keys_bitstring' columns in the test set\n",
    "test_df = test_df.drop(columns=['maccs_keys', 'maccs_keys_bitstring'])\n",
    "\n",
    "# Concatenate the new MACCS keys features with the original test dataframe\n",
    "test_df = pd.concat([test_df, test_maccs_keys_df], axis=1)\n",
    "\n",
    "# Define the features and target variables for the test set\n",
    "X_test = test_df.drop(columns=['SMILES', 'PKM2_inhibition', 'ERK2_inhibition'])\n",
    "y_test = test_df[['PKM2_inhibition', 'ERK2_inhibition']]\n",
    "\n",
    "# Remove rows with missing target values in y_test and corresponding rows in X_test_aligned\n",
    "non_missing_indices = y_test.dropna().index\n",
    "X_test = X_test.loc[non_missing_indices]\n",
    "y_test = y_test.loc[non_missing_indices]\n",
    "\n",
    "# Convert data to float32 for the test set\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Align the columns of the test set to match those of the training set\n",
    "X_test_aligned = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Make predictions on the cleaned test set\n",
    "y_test_pred_cleaned = clf.predict(X_test_aligned)\n",
    "\n",
    "# Model Accuracy on the cleaned test set\n",
    "test_accuracy_cleaned = metrics.accuracy_score(y_test, y_test_pred_cleaned)\n",
    "print(\"Test Accuracy:\", test_accuracy_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
